{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import initializers\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense, Activation, Bidirectional, Embedding, GRU, Concatenate\n",
    "from keras.layers.core import Reshape, Dropout\n",
    "from keras.models import Model, Input, save_model, load_model\n",
    "\n",
    "# Params\n",
    "MAX_SEQUENCE_LENGTH = 20000\n",
    "DISC_HIDDEN_SIZE_LSTM = 64\n",
    "DISC_HIDDEN_SIZE_DENSE = 4612\n",
    "dropout = 0.2\n",
    "weight_decay = 0.25\n",
    "samples_per_epoch = 12000\n",
    "learning_rate = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_layer_q = Embedding(\n",
    "            input_dim=20000,\n",
    "            output_dim=300,\n",
    "            input_length=MAX_SEQUENCE_LENGTH,\n",
    "            trainable=False)\n",
    "\n",
    "embeddings_layer_d = Embedding(\n",
    "            input_dim=20000,\n",
    "            output_dim=300,\n",
    "            input_length=MAX_SEQUENCE_LENGTH,\n",
    "            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from six.moves import zip\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.legacy import interfaces\n",
    "\n",
    "from keras.optimizers import Optimizer\n",
    "\n",
    "\n",
    "class AdamW(Optimizer):\n",
    "    \"\"\"AdamW optimizer.\n",
    "    Default parameters follow those provided in the original paper.\n",
    "    # Arguments\n",
    "        lr: float >= 0. Learning rate.\n",
    "        beta_1: float, 0 < beta < 1. Generally close to 1.\n",
    "        beta_2: float, 0 < beta < 1. Generally close to 1.\n",
    "        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n",
    "        decay: float >= 0. Learning rate decay over each update.\n",
    "        weight_decay: float >= 0. Weight decay (L2 penalty) (default: 0.025).\n",
    "        batch_size: integer >= 1. Batch size used during training.\n",
    "        samples_per_epoch: integer >= 1. Number of samples (training points) per epoch.\n",
    "        epochs: integer >= 1. Total number of epochs for training.\n",
    "    # References\n",
    "        - [Adam - A Method for Stochastic Optimization](http://arxiv.org/abs/1412.6980v8)\n",
    "        - [Fixing Weight Decay Regularization in Adam](https://arxiv.org/abs/1711.05101)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999,\n",
    "                 epsilon=None, decay=0., weight_decay=0.025,\n",
    "                 batch_size=1, samples_per_epoch=1,\n",
    "                 epochs=1, **kwargs):\n",
    "        super(AdamW, self).__init__(**kwargs)\n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
    "            self.lr = K.variable(lr, name='lr')\n",
    "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
    "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
    "            self.decay = K.variable(decay, name='decay')\n",
    "            self.weight_decay = K.variable(weight_decay, name='weight_decay')\n",
    "            self.batch_size = K.variable(batch_size, name='batch_size')\n",
    "            self.samples_per_epoch = K.variable(samples_per_epoch, name='samples_per_epoch')\n",
    "            self.epochs = K.variable(epochs, name='epochs')\n",
    "        if epsilon is None:\n",
    "            epsilon = K.epsilon()\n",
    "        self.epsilon = epsilon\n",
    "        self.initial_decay = decay\n",
    "\n",
    "    @interfaces.legacy_get_updates_support\n",
    "    def get_updates(self, loss, params):\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        self.updates = [K.update_add(self.iterations, 1)]\n",
    "\n",
    "        lr = self.lr\n",
    "        if self.initial_decay > 0:\n",
    "            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n",
    "                                                      K.dtype(self.decay))))\n",
    "\n",
    "        t = K.cast(self.iterations, K.floatx()) + 1\n",
    "        '''Bias corrections according to the Adam paper\n",
    "        '''\n",
    "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n",
    "                     (1. - K.pow(self.beta_1, t)))\n",
    "\n",
    "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        self.weights = [self.iterations] + ms + vs\n",
    "\n",
    "        for p, g, m, v in zip(params, grads, ms, vs):\n",
    "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
    "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
    "\n",
    "            '''Schedule multiplier eta_t = 1 for simple AdamW\n",
    "            According to the AdamW paper, eta_t can be fixed, decay, or \n",
    "            also be used for warm restarts (AdamWR to come). \n",
    "            '''\n",
    "            eta_t = 1.\n",
    "            p_t = p - eta_t * (lr_t * m_t / (K.sqrt(v_t) + self.epsilon))\n",
    "            if self.weight_decay != 0:\n",
    "                '''Normalized weight decay according to the AdamW paper\n",
    "                '''\n",
    "                w_d = self.weight_decay * K.sqrt(self.batch_size / (self.samples_per_epoch * self.epochs))\n",
    "                p_t = p_t - eta_t * (w_d * p)\n",
    "\n",
    "            self.updates.append(K.update(m, m_t))\n",
    "            self.updates.append(K.update(v, v_t))\n",
    "            new_p = p_t\n",
    "\n",
    "            # Apply constraints.\n",
    "            if getattr(p, 'constraint', None) is not None:\n",
    "                new_p = p.constraint(new_p)\n",
    "\n",
    "            self.updates.append(K.update(p, new_p))\n",
    "        return self.updates\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'lr': float(K.get_value(self.lr)),\n",
    "                  'beta_1': float(K.get_value(self.beta_1)),\n",
    "                  'beta_2': float(K.get_value(self.beta_2)),\n",
    "                  'decay': float(K.get_value(self.decay)),\n",
    "                  'weight_decay': float(K.get_value(self.weight_decay)),\n",
    "                  'batch_size': int(K.get_value(self.batch_size)),\n",
    "                  'samples_per_epoch': int(K.get_value(self.samples_per_epoch)),\n",
    "                  'epochs': int(K.get_value(self.epochs)),\n",
    "                  'epsilon': self.epsilon}\n",
    "        base_config = super(AdamW, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adamw = AdamW(batch_size=8, samples_per_epoch=samples_per_epoch,\n",
    "                      epochs=12000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_query:0' shape=(?, 20000) dtype=int32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_input_q = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='input_query')\n",
    "sequence_input_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x7ff908598dd8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sequences_q = embeddings_layer_q(sequence_input_q)\n",
    "embeddings_layer_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'bidirectional_1/concat:0' shape=(?, ?, 128) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_q_in = Bidirectional(GRU(DISC_HIDDEN_SIZE_LSTM, return_sequences=True, activation='elu', dropout=dropout, recurrent_dropout=dropout))(embedded_sequences_q)\n",
    "lstm_q_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'bidirectional_2/concat:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_q_out = Bidirectional(GRU(DISC_HIDDEN_SIZE_LSTM, return_sequences=False, activation='elu', dropout=dropout, recurrent_dropout=dropout))(lstm_q_in)\n",
    "lstm_q_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documents Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_doc:0' shape=(?, 20000) dtype=int32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_input_d = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='input_doc')\n",
    "sequence_input_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_2/embedding_lookup:0' shape=(?, 20000, 300) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sequences_d = embeddings_layer_d(sequence_input_d)\n",
    "embedded_sequences_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'bidirectional_3/concat:0' shape=(?, ?, 128) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_d_in = Bidirectional(GRU(DISC_HIDDEN_SIZE_LSTM, return_sequences=True, activation='elu', dropout=dropout, recurrent_dropout=dropout))(embedded_sequences_d)\n",
    "lstm_d_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'bidirectional_4/concat:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_d_out = Bidirectional(GRU(DISC_HIDDEN_SIZE_LSTM, return_sequences=False, activation='elu', dropout=dropout, recurrent_dropout=dropout))(lstm_d_in)\n",
    "lstm_d_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate and then Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 256) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Concatenate()([lstm_q_out, lstm_d_out])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dropout_1/cond/Merge:0' shape=(?, 256) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Dropout(dropout)(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'merged_input/Elu:0' shape=(?, 4612) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Dense(DISC_HIDDEN_SIZE_DENSE,\n",
    "          activation='elu',\n",
    "          kernel_regularizer=regularizers.l2(),\n",
    "          kernel_initializer=initializers.random_normal(stddev=0.01),\n",
    "          name='merged_input')(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_1/Elu:0' shape=(?, 1) dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Dense(1, activation='elu')(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'reshape_1/Reshape:0' shape=(?, ?) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = Reshape([-1])(x)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = Activation('sigmoid', name='prob')(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7ff8b6640b38>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(inputs=[sequence_input_q, sequence_input_d], outputs=[prob])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_query (InputLayer)        (None, 20000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_doc (InputLayer)          (None, 20000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 20000, 300)   6000000     input_query[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 20000, 300)   6000000     input_doc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 20000, 128)   140160      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 20000, 128)   140160      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 128)          74112       bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 128)          74112       bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "merged_input (Dense)            (None, 4612)         1185284     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            4613        merged_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1)            0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "prob (Activation)               (None, 1)            0           reshape_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 13,618,441\n",
      "Trainable params: 1,618,441\n",
      "Non-trainable params: 12,000,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7ff8b6640b38>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "                      optimizer=adamw,\n",
    "                      metrics=['accuracy'])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='discriminator.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"712pt\" viewBox=\"0.00 0.00 534.00 712.00\" width=\"534pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 708)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-708 530,-708 530,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140706442751336 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140706442751336</title>\n",
       "<polygon fill=\"none\" points=\"52.5,-667 52.5,-703 201.5,-703 201.5,-667 52.5,-667\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127\" y=\"-681.3\">input_query: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140707563671000 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140707563671000</title>\n",
       "<polygon fill=\"none\" points=\"46.5,-593 46.5,-629 207.5,-629 207.5,-593 46.5,-593\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127\" y=\"-607.3\">embedding_1: Embedding</text>\n",
       "</g>\n",
       "<!-- 140706442751336&#45;&gt;140707563671000 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140706442751336-&gt;140707563671000</title>\n",
       "<path d=\"M127,-666.937C127,-658.807 127,-648.876 127,-639.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"130.5,-639.441 127,-629.441 123.5,-639.441 130.5,-639.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140706211752984 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140706211752984</title>\n",
       "<polygon fill=\"none\" points=\"330,-667 330,-703 468,-703 468,-667 330,-667\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"399\" y=\"-681.3\">input_doc: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140707563671112 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140707563671112</title>\n",
       "<polygon fill=\"none\" points=\"318.5,-593 318.5,-629 479.5,-629 479.5,-593 318.5,-593\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"399\" y=\"-607.3\">embedding_2: Embedding</text>\n",
       "</g>\n",
       "<!-- 140706211752984&#45;&gt;140707563671112 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140706211752984-&gt;140707563671112</title>\n",
       "<path d=\"M399,-666.937C399,-658.807 399,-648.876 399,-639.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"402.5,-639.441 399,-629.441 395.5,-639.441 402.5,-639.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140706442674472 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140706442674472</title>\n",
       "<polygon fill=\"none\" points=\"0,-519 0,-555 254,-555 254,-519 0,-519\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127\" y=\"-533.3\">bidirectional_1(gru_1): Bidirectional(GRU)</text>\n",
       "</g>\n",
       "<!-- 140707563671000&#45;&gt;140706442674472 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140707563671000-&gt;140706442674472</title>\n",
       "<path d=\"M127,-592.937C127,-584.807 127,-574.876 127,-565.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"130.5,-565.441 127,-555.441 123.5,-565.441 130.5,-565.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140706203328184 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140706203328184</title>\n",
       "<polygon fill=\"none\" points=\"272,-519 272,-555 526,-555 526,-519 272,-519\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"399\" y=\"-533.3\">bidirectional_3(gru_3): Bidirectional(GRU)</text>\n",
       "</g>\n",
       "<!-- 140707563671112&#45;&gt;140706203328184 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140707563671112-&gt;140706203328184</title>\n",
       "<path d=\"M399,-592.937C399,-584.807 399,-574.876 399,-565.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"402.5,-565.441 399,-555.441 395.5,-565.441 402.5,-565.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140706210403048 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140706210403048</title>\n",
       "<polygon fill=\"none\" points=\"0,-445 0,-481 254,-481 254,-445 0,-445\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127\" y=\"-459.3\">bidirectional_2(gru_2): Bidirectional(GRU)</text>\n",
       "</g>\n",
       "<!-- 140706442674472&#45;&gt;140706210403048 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140706442674472-&gt;140706210403048</title>\n",
       "<path d=\"M127,-518.937C127,-510.807 127,-500.876 127,-491.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"130.5,-491.441 127,-481.441 123.5,-491.441 130.5,-491.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140706196270216 -->\n",
       "<g class=\"node\" id=\"node8\"><title>140706196270216</title>\n",
       "<polygon fill=\"none\" points=\"272,-445 272,-481 526,-481 526,-445 272,-445\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"399\" y=\"-459.3\">bidirectional_4(gru_4): Bidirectional(GRU)</text>\n",
       "</g>\n",
       "<!-- 140706203328184&#45;&gt;140706196270216 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140706203328184-&gt;140706196270216</title>\n",
       "<path d=\"M399,-518.937C399,-510.807 399,-500.876 399,-491.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"402.5,-491.441 399,-481.441 395.5,-491.441 402.5,-491.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140707563774024 -->\n",
       "<g class=\"node\" id=\"node9\"><title>140707563774024</title>\n",
       "<polygon fill=\"none\" points=\"179,-371 179,-407 347,-407 347,-371 179,-371\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"263\" y=\"-385.3\">concatenate_1: Concatenate</text>\n",
       "</g>\n",
       "<!-- 140706210403048&#45;&gt;140707563774024 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>140706210403048-&gt;140707563774024</title>\n",
       "<path d=\"M159.23,-444.937C177.894,-435.056 201.584,-422.514 221.615,-411.91\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"223.33,-414.962 230.53,-407.19 220.054,-408.776 223.33,-414.962\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140706196270216&#45;&gt;140707563774024 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>140706196270216-&gt;140707563774024</title>\n",
       "<path d=\"M366.77,-444.937C348.106,-435.056 324.416,-422.514 304.385,-411.91\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"305.946,-408.776 295.47,-407.19 302.67,-414.962 305.946,-408.776\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140706442748648 -->\n",
       "<g class=\"node\" id=\"node10\"><title>140706442748648</title>\n",
       "<polygon fill=\"none\" points=\"200.5,-297 200.5,-333 325.5,-333 325.5,-297 200.5,-297\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"263\" y=\"-311.3\">dropout_1: Dropout</text>\n",
       "</g>\n",
       "<!-- 140707563774024&#45;&gt;140706442748648 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>140707563774024-&gt;140706442748648</title>\n",
       "<path d=\"M263,-370.937C263,-362.807 263,-352.876 263,-343.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"266.5,-343.441 263,-333.441 259.5,-343.441 266.5,-343.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140706189392360 -->\n",
       "<g class=\"node\" id=\"node11\"><title>140706189392360</title>\n",
       "<polygon fill=\"none\" points=\"196,-223 196,-259 330,-259 330,-223 196,-223\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"263\" y=\"-237.3\">merged_input: Dense</text>\n",
       "</g>\n",
       "<!-- 140706442748648&#45;&gt;140706189392360 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>140706442748648-&gt;140706189392360</title>\n",
       "<path d=\"M263,-296.937C263,-288.807 263,-278.876 263,-269.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"266.5,-269.441 263,-259.441 259.5,-269.441 266.5,-269.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140706189392752 -->\n",
       "<g class=\"node\" id=\"node12\"><title>140706189392752</title>\n",
       "<polygon fill=\"none\" points=\"212,-149 212,-185 314,-185 314,-149 212,-149\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"263\" y=\"-163.3\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 140706189392360&#45;&gt;140706189392752 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>140706189392360-&gt;140706189392752</title>\n",
       "<path d=\"M263,-222.937C263,-214.807 263,-204.876 263,-195.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"266.5,-195.441 263,-185.441 259.5,-195.441 266.5,-195.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140706189391744 -->\n",
       "<g class=\"node\" id=\"node13\"><title>140706189391744</title>\n",
       "<polygon fill=\"none\" points=\"200.5,-75 200.5,-111 325.5,-111 325.5,-75 200.5,-75\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"263\" y=\"-89.3\">reshape_1: Reshape</text>\n",
       "</g>\n",
       "<!-- 140706189392752&#45;&gt;140706189391744 -->\n",
       "<g class=\"edge\" id=\"edge12\"><title>140706189392752-&gt;140706189391744</title>\n",
       "<path d=\"M263,-148.937C263,-140.807 263,-130.876 263,-121.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"266.5,-121.441 263,-111.441 259.5,-121.441 266.5,-121.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140706189392584 -->\n",
       "<g class=\"node\" id=\"node14\"><title>140706189392584</title>\n",
       "<polygon fill=\"none\" points=\"210,-1 210,-37 316,-37 316,-1 210,-1\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"263\" y=\"-15.3\">prob: Activation</text>\n",
       "</g>\n",
       "<!-- 140706189391744&#45;&gt;140706189392584 -->\n",
       "<g class=\"edge\" id=\"edge13\"><title>140706189391744-&gt;140706189392584</title>\n",
       "<path d=\"M263,-74.937C263,-66.8072 263,-56.8761 263,-47.7047\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"266.5,-47.4406 263,-37.4407 259.5,-47.4407 266.5,-47.4406\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'input_query_6:0' shape=(?, 20000) dtype=int32>, <tf.Tensor 'input_doc_6:0' shape=(?, 20000) dtype=int32>]\n",
      "Tensor(\"prob_6/Sigmoid:0\", shape=(?, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "inp = model.input\n",
    "print(inp)\n",
    "out = model.get_layer(\"prob\").output\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize queries\n",
      "[nltk_data] Downloading package stopwords to /home/lukas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Found 1247 unique tokens.\n",
      "Tokenize documents\n",
      "[nltk_data] Downloading package stopwords to /home/lukas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Found 7709 unique tokens.\n",
      "Found 1 training data.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 20000\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "WORKDIR = '/home/lukas/git-projects/lstm-irgan'\n",
    "DOCUMENTS_DIR = WORKDIR + '/data/wikiclir/dev.docs'  #'/data/example/documents/'\n",
    "QUERIES = WORKDIR + '/data/wikiclir/dev.queries' #'/data/example/queries.txt'\n",
    "LABELLED_DATA = WORKDIR + '/data/wikiclir/dev.qrel' #'/data/example/labelled_data.txt'\n",
    "\n",
    "def __get_documents():\n",
    "    path = DOCUMENTS_DIR\n",
    "    documents = {}\n",
    "    doc_ids = []\n",
    "\n",
    "    with open(path) as f:\n",
    "        content = f.readlines()\n",
    "        for line in content[:100]:\n",
    "            values = line.split(\"\\t\", 1)\n",
    "            id = int(values[0])\n",
    "            text = values[1]\n",
    "            documents[id] = text\n",
    "            doc_ids.append(id)\n",
    "    return documents, doc_ids\n",
    "\n",
    "\n",
    "def __get_queries():\n",
    "    path = QUERIES\n",
    "    queries = {}\n",
    "    query_ids = []\n",
    "\n",
    "    with open(path) as f:\n",
    "        content = f.readlines()\n",
    "        for line in content[:100]:\n",
    "            values = line.split(\"\\t\", 1)\n",
    "            id = int(values[0])\n",
    "            text = values[1]\n",
    "            queries[id] = text\n",
    "            query_ids.append(id)\n",
    "    return queries, query_ids\n",
    "\n",
    "\n",
    "def __get_ratings():\n",
    "    path = LABELLED_DATA\n",
    "    ratings = {}\n",
    "\n",
    "    with open(path) as f:\n",
    "        content = f.readlines()\n",
    "        for line in content[:100]:\n",
    "            values = line.split(\"\\t\")\n",
    "            query = int(values[0])\n",
    "            text = int(values[2])\n",
    "            rating = float(values[3])\n",
    "\n",
    "            if query in ratings.keys():\n",
    "                ratings[query][text] = rating\n",
    "            else:\n",
    "                ratings[query] = {text: rating}\n",
    "\n",
    "    return ratings\n",
    "\n",
    "\n",
    "def __filter_stop_words(texts, stop_words):\n",
    "    for i, text in enumerate(texts):\n",
    "        new_text = [word for word in text.split() if word not in stop_words]\n",
    "        texts[i] = ' '.join(new_text)\n",
    "    return texts\n",
    "\n",
    "\n",
    "def __init_tokenizer(text_data, max_sequence_length):\n",
    "    texts = list(text_data.values())\n",
    "    ids = list(text_data.keys())\n",
    "\n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.update(['.', ',', '\"', \"'\", ':', ';', '(', ')', '[', ']', '{', '}'])\n",
    "    texts = __filter_stop_words(texts, stop_words)\n",
    "\n",
    "    # finally, vectorize the text samples into a 2D integer tensor\n",
    "    tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "    data = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "    text_data_sequenced = {}\n",
    "    for i, text in enumerate(data):\n",
    "        text_data_sequenced[ids[i]] = text\n",
    "\n",
    "    return tokenizer, text_data_sequenced\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    documents_data, doc_ids = __get_documents()\n",
    "    queries_data, query_ids = __get_queries()\n",
    "    ratings_data = __get_ratings()\n",
    "\n",
    "    print('Tokenize queries')\n",
    "    tokenizer_q, queries_data = __init_tokenizer(queries_data, MAX_SEQUENCE_LENGTH)\n",
    "    print('Tokenize documents')\n",
    "    tokenizer_d, documents_data = __init_tokenizer(documents_data, MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "    print('Found %s training data.' % len(ratings_data))\n",
    "\n",
    "    return query_ids, ratings_data, documents_data, queries_data, tokenizer_q, tokenizer_d\n",
    "\n",
    "query_ids, ratings_data, documents_data, queries_data, tokenizer_q, tokenizer_d = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([   0,    0,    0, ...,   23, 3388, 1496], dtype=int32), array([   0,    0,    0, ...,  286,  591, 2098], dtype=int32), array([  0,   0,   0, ..., 169, 503, 188], dtype=int32)]\n",
      "[array([  0,   0,   0, ...,   2, 204,  28], dtype=int32), array([  0,   0,   0, ...,   2, 204,  28], dtype=int32), array([  0,   0,   0, ...,   2, 204,  28], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "docs = [value for key, value in list(documents_data.items())[:3]]\n",
    "key, value = list(queries_data.items())[0]\n",
    "queries = [value]*3\n",
    "prob = [0.2, 0.5, 0,1]\n",
    "print(docs)\n",
    "print(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'input_query_6:0' shape=(?, 20000) dtype=int32>, <tf.Tensor 'input_doc_6:0' shape=(?, 20000) dtype=int32>, <tf.Tensor 'bidirectional_1/keras_learning_phase:0' shape=() dtype=bool>]\n",
      "<keras.backend.tensorflow_backend.Function object at 0x7f64855013c8>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.00151122],\n",
       "       [-0.00453931],\n",
       "       [-0.00172484]], dtype=float32)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_reward(train_data_queries, train_data_documents):\n",
    "    inputs = model.inputs + [K.learning_phase()]\n",
    "    print(inputs)\n",
    "    out = model.get_layer(\"prob\").output\n",
    "    functor = K.function(inputs, [out])\n",
    "    print(functor)\n",
    "    layer_outs = functor([train_data_queries, train_data_documents, 1.])\n",
    "    return (layer_outs[0] - 0.5) * 2\n",
    "\n",
    "reward = get_reward(queries, docs)\n",
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00094205],\n",
       "       [-0.00294149],\n",
       "       [-0.00079733]], dtype=float32)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_preresult(train_data_queries, train_data_documents):\n",
    "    return (model.predict([train_data_queries, train_data_documents]) - 0.5) * 2\n",
    "    \n",
    "preresult = get_preresult(queries, docs)\n",
    "preresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train(train_data_queries, train_data_documents, train_data_label):\n",
    "    model.train_on_batch([train_data_queries, train_data_documents], train_data_label)\n",
    "    \n",
    "# choose data\n",
    "choose_queries = np.array(queries)\n",
    "choose_documents = np.array(docs)\n",
    "\n",
    "# prepare pos and neg label\n",
    "pred_data_label = [1.0] * 1\n",
    "pred_data_label.extend([0.0] * 2)\n",
    "pred_data_label = np.asarray(pred_data_label)\n",
    "\n",
    "train(choose_queries, choose_documents, pred_data_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
